{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a PARTICLE PERSPECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalClock():\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "    \n",
    "    def tick(self):\n",
    "        return -np.log(np.random.rand())/self.rate\n",
    "    \n",
    "class Particle():\n",
    "    def __init__(self, start):\n",
    "        self.pos = []\n",
    "        self.transition_times = []\n",
    "\n",
    "        self.pos.append(start)\n",
    "        self.transition_times.append(0)\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.num_particles = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_bar= [0.2173913  0.14906832 0.26086957 0.1863354  0.1863354 ]\n"
     ]
    }
   ],
   "source": [
    "Lambda = [\n",
    "[0, 2/5, 1/5, 0, 0],\n",
    "[0, 0, 3/4, 1/4, 0],\n",
    "[1/2, 0, 0, 1/3, 0],\n",
    "[0, 0, 1/3, 0, 2/3],\n",
    "[0, 1/3, 0, 1/3, 0]]\n",
    "\n",
    "w = np.sum(Lambda, axis=1)\n",
    "w_star = np.max(w)\n",
    "# compute the off-diagonal part of Q\n",
    "P_bar = Lambda/w_star \n",
    "# add the diagonal part\n",
    "P_bar = P_bar + np.diag(np.ones(len(w))-np.sum(P_bar,axis=1))\n",
    "\n",
    "# compute dominant eigenvector\n",
    "values,vectors = np.linalg.eig(P_bar.T)\n",
    "index = np.argmax(values.real)\n",
    "pi_bar = vectors[:,index].real\n",
    "pi_bar = pi_bar/np.sum(pi_bar)\n",
    "print(\"pi_bar=\", pi_bar)\n",
    "\n",
    "nstates = len(pi_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = [Particle(2) for _ in range(100)]\n",
    "node_ids = [0,1,2,3,4] # represent o a b c d\n",
    "\n",
    "clock = GlobalClock(rate = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(n_steps):\n",
    "    t_next = clock.tick()\n",
    "\n",
    "    chosen_particle_index = np.random.randint(low = 0, high = len(particles))\n",
    "    chosen_particle = particles[chosen_particle_index]\n",
    "\n",
    "    chosen_particle.pos.append(np.random.choice(node_ids, p=P_bar[chosen_particle.pos[-1],:]))\n",
    "    chosen_particle.transition_times.append(chosen_particle.transition_times[-1] + t_next)\n",
    "\n",
    "    for i in range(len(particles)):\n",
    "        if i != chosen_particle_index:\n",
    "            particles[i].pos.append(particles[i].pos[-1])\n",
    "            particles[i].transition_times.append(particles[i].transition_times[-1] + t_next)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_return_time(particle, padded_endtime, return_pos):\n",
    "    intervals = np.diff(particle.transition_times, n=1, append = particle.transition_times[-1] + padded_endtime)\n",
    "    pos = np.array(particle.pos)\n",
    "    visits = np.argwhere(pos == return_pos).flatten()\n",
    "\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    temp = 0\n",
    "    for i in range(len(visits) - 1):\n",
    "        begin = visits[i]\n",
    "        end = visits[i+1]\n",
    "\n",
    "        if end >  begin + 1:\n",
    "            for j in range(begin, end):\n",
    "                sum = sum + intervals[j]\n",
    "            sum = sum + temp\n",
    "            count = count + 1\n",
    "\n",
    "            temp = 0\n",
    "        else:\n",
    "            temp = temp + intervals[begin]\n",
    "\n",
    "    return sum/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_endtime = clock.tick()\n",
    "\n",
    "l = []\n",
    "\n",
    "for particle in particles:\n",
    "    l.append(avg_return_time(particle, padded_endtime, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(l)\n",
    "variance = np.var(l)\n",
    "median = np.median(l)\n",
    "first_quartile = np.quantile(l, q = 0.25)\n",
    "third_quartile = np.quantile(l, q = 0.75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.586335781609094\n",
      "variance: 0.07093242964695831\n",
      "median: 4.573194970853018\n",
      "Q1: 4.4042378695426265\n",
      "Q3: 4.7286186343348335\n"
     ]
    }
   ],
   "source": [
    "print(f'mean: {mean}')\n",
    "print(f'variance: {variance}')\n",
    "print(f'median: {median}')\n",
    "print(f'Q1: {first_quartile}')\n",
    "print(f'Q3: {third_quartile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b NODE PERSPECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = [0,1,2,3,4] #represent o,a,b,c,d\n",
    "nodes = [Node(id) for id in node_ids ]\n",
    "\n",
    "nodes[0].num_particles = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_node = 0\n",
    "\n",
    "time = clock.tick()\n",
    "counter = 0\n",
    "\n",
    "while time < threshold:\n",
    "    chosen_node = np.random.choice(node_ids, p= np.array([nodes[i].num_particles for i in range(len(nodes))]) / 1000)\n",
    "    to_node = np.random.choice(node_ids, p=P_bar[chosen_node,:])\n",
    "\n",
    "    nodes[chosen_node].num_particles -= 1\n",
    "    nodes[to_node].num_particles +=1\n",
    "\n",
    "    time += clock.tick()\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.234, 0.153, 0.261, 0.19, 0.162]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nodes[i].num_particles / 1000 for i in range(len(nodes))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pi_bar= [0.2173913  0.14906832 0.26086957 0.1863354  0.1863354 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NetWorkDynamic2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
